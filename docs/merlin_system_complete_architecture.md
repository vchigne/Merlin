# Arquitectura Completa del Sistema Merlin

## ğŸ¯ Resumen Ejecutivo

Merlin es un sistema de orquestaciÃ³n distribuido diseÃ±ado para automatizar procesos empresariales complejos. Combina agentes autÃ³nomos en .NET con un coordinador central en Hasura GraphQL, ejecutando pipelines con mÃºltiples tipos de operaciones: consultas SQL, transferencias SFTP, comandos del sistema, compresiÃ³n de archivos y llamadas recursivas a otros pipelines.

## ğŸ—ï¸ Arquitectura General del Sistema

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”    â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Dashboard     â”‚    â”‚  Hasura GraphQL â”‚    â”‚   Merlin Agent  â”‚
â”‚   (Monitoring)  â”‚â—„â”€â”€â–ºâ”‚  (Coordinator)  â”‚â—„â”€â”€â–ºâ”‚   (Executor)    â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚                       â”‚                       â”‚
         â–¼                       â–¼                       â–¼
   - Real-time UI          - Job Queue              - 4 Workers
   - Agent Status          - Pipeline Storage       - 5 Runners  
   - Pipeline Design       - Logging Aggregation    - Auto-Update
   - Error Analysis        - GraphQL API            - Heartbeat
```

---

## ğŸ¤– Arquitectura del Agente Merlin

### **Sistema Multi-Worker Paralelo**

```csharp
// 4 Workers ejecutÃ¡ndose simultÃ¡neamente en cada agente
services.AddHostedService<Worker>();        // CoordinaciÃ³n y updates
services.AddHostedService<PingWorker>();    // Heartbeat cada ~60s
services.AddHostedService<MemoryLogWorker>(); // Buffer de logs
services.AddHostedService<QueueWorker>();   // Procesamiento de jobs
```

#### **1. Worker Principal**
- **VerificaciÃ³n de actualizaciones** automÃ¡ticas desde Hasura
- **CoordinaciÃ³n general** del ciclo de vida del agente
- **Auto-limpieza** de archivos temporales
- **GestiÃ³n de configuraciÃ³n** desde variables de entorno

#### **2. PingWorker - Sistema de Heartbeat**
- **Pings regulares** cada ~60 segundos a Hasura
- **InformaciÃ³n del sistema**: OS, IPs, directorio de trabajo, versiÃ³n
- **ActualizaciÃ³n** de `is_healthy` y `last_ping_at`
- **DetecciÃ³n automÃ¡tica** de agentes offline por el dashboard

#### **3. MemoryLogWorker - GestiÃ³n de Logs**
- **Buffer optimizado** en memoria durante ejecuciÃ³n de jobs
- **Flush automÃ¡tico** a Hasura en formato JSON estructurado
- **Cola de respaldo** con mÃ¡ximo 100 bloques si falla conexiÃ³n
- **ReenvÃ­o automÃ¡tico** cuando la conexiÃ³n se restablece

#### **4. QueueWorker - Procesador de Jobs**
- **Polling continuo** de `PipelineJobQueue` en Hasura
- **ConstrucciÃ³n de cadenas** de dependencia entre pipeline units
- **EjecuciÃ³n secuencial** con runners especializados
- **Manejo de estados** (pending â†’ running â†’ completed/failed)

### **Modos de Despliegue Flexibles**

#### **Desarrollo/Debug**
```bash
merlin-agent normal --contentRoot "C:\path"
```
- EjecuciÃ³n continua con logging visible en consola
- Ideal para testing y desarrollo

#### **ProducciÃ³n Enterprise**
```bash
merlin-agent winservice --contentRoot "C:\path"
```
- Servicio Windows nativo con `sc.exe`
- Auto-start y recuperaciÃ³n automÃ¡tica
- Logging solo a archivos y Hasura

#### **Entornos Restringidos**
```bash
merlin-agent onetime --contentRoot "C:\path"
```
- EjecuciÃ³n Ãºnica para Windows Task Scheduler
- Sin servicios persistentes requeridos

### **Sistema de Logging Avanzado**

```csharp
// ConfiguraciÃ³n multi-target optimizada
var batchLogFile = new AsyncTargetWrapper("batchLogFile", logfile) {
    BatchSize = 1000,  // Escritura por lotes
    OverflowAction = AsyncTargetWrapperOverflowAction.Discard
};

// JSON estructurado para Hasura
var jsonLayout = new NLog.Layouts.JsonLayout() {
    Attributes = {
        new JsonAttribute("pipeline_job_id", "${event-properties:PipelineJobId}"),
        new JsonAttribute("pipeline_unit_id", "${event-properties:PipelineUnitId}"),
        new JsonAttribute("pipeline_unit_context_id", "${event-properties:PipelineUnitContextId}"),
        new JsonAttribute("date", "${longdate:universalTime=true}+00:00"),
        new JsonAttribute("level", "${level:uppercase=true}"),
        new JsonAttribute("message", "${message}"),
        new JsonAttribute("callsite", "${callsite}"),
        new JsonAttribute("exception", "${exception:format=type}"),
        new JsonAttribute("exception_message", "${exception:format=message}"),
        new JsonAttribute("exception_stack_trace", "${exception:format=stacktrace}")
    }
};
```

**CaracterÃ­sticas:**
- **Logging asÃ­ncrono** con batches de 1000 logs para performance
- **RotaciÃ³n automÃ¡tica** a los 5MB con 5 archivos histÃ³ricos
- **Contexto enriquecido** con PipelineJobId, PipelineUnitId, y ContextId
- **ActivaciÃ³n dinÃ¡mica** del memory target durante ejecuciÃ³n de jobs
- **Cola de respaldo** resiliente con reenvÃ­o automÃ¡tico

---

## ğŸ”§ Sistema de Runners Especializados

### **1. QueryQueueRunner - Orquestador de Datos**

```csharp
// EjecuciÃ³n ordenada con reintentos por query
var sortedQueries = queryQueue.Queries.OrderBy(q => q.Order);
foreach (var query in sortedQueries) {
    QueryExecutionResult result = _runQueryWithRetry(query, tryCount: 0);
    if (query.ReturnOutput && result.Output != null) {
        _output.AddRange(result.Output); // Archivos CSV/TXT generados
    }
}
```

**Capacidades:**
- **Soporte dual**: MSSQL Server nativo y ODBC universal
- **Reintentos independientes** con `RetryCount` y `RetryAfterMilliseconds`
- **ConfiguraciÃ³n granular**: encoding, separadores, headers, chunks, formato de fechas
- **GeneraciÃ³n de archivos** CSV/TXT con paths en el output para siguiente unidad

### **2. CommandRunner - Motor de EjecuciÃ³n**

```csharp
// 3 modos de ejecuciÃ³n diferenciados
if (unit.Command.RawScript != null) {
    return runCommandWithRawScript(startInfo, unit);  // Scripts multi-lÃ­nea
} else if (unit.Command.Instant) {
    return runInstantCommand(startInfo, unit);        // Comandos rÃ¡pidos
} else {
    return runNormalCommand(startInfo, unit);         // Streaming en tiempo real
}
```

**CaracterÃ­sticas:**
- **Timeout robusto** con terminaciÃ³n forzada de procesos colgados
- **Captura completa** de stdout y stderr
- **Working directory** configurable por comando
- **Script injection** para aplicaciones interactivas

### **3. SFTPRunner - Transferidor Seguro**

```csharp
// Upload/Download con manejo robusto de errores
client.HostKeyReceived += delegate { e.CanTrust = true; }; // Bypass SSL automÃ¡tico
foreach (var f in fsUploader) {
    using (var s = File.OpenRead(f.Input)) {
        client.UploadFile(s, f.Output);
        if (f.ReturnOutput) _output.Add(f.Output); // Path remoto
    }
}
```

**Funciones:**
- **Bypass SSL automÃ¡tico** para certificados self-signed
- **Transferencias mÃºltiples** con conteo de Ã©xitos vs fallos
- **Puerto configurable** (default 22)
- **Logging detallado** de cada transferencia individual

### **4. ZipRunner - Compactador Inteligente**

```csharp
// CompresiÃ³n con wildcards y directorios
if (Directory.Exists(fStream.Input) && fStream.WildcardExp != null) {
    string[] wfiles = Directory.GetFiles(fStream.Input, fStream.WildcardExp);
    foreach (string wfile in wfiles) {
        zip.CreateEntryFromFile(wfile, Path.GetFileName(wfile), CompressionLevel.Optimal);
    }
}
```

**CaracterÃ­sticas:**
- **Wildcards** para mÃºltiples archivos con patrones (*.csv, *.txt)
- **CompresiÃ³n Ã³ptima** automÃ¡tica
- **Sobrescritura** de archivos existentes
- **DescompresiÃ³n** con overwrite para actualizaciones

### **5. PipelineCallRunner - Recursivo AsÃ­ncrono**

```csharp
// Ejecuta otro pipeline de forma asÃ­ncrona
public async Task<bool> CallPipeline(PipelineUnit unit) {
    GQLCallPipeline call = new GQLCallPipeline();
    var response = await HasuraClient.graphQLClient.SendMutationAsync<InsertMerlinAgentPipelineJobQueueResponse>(call.callPipeline(unit.CallPipeline));
    
    return response.Data.insertMerlinAgentPipelineJobQueue.AffectedRows > 0;
}
```

**Permite:**
- **ReutilizaciÃ³n** de pipelines complejos
- **Workflows condicionales** basados en resultados
- **Procesamiento paralelo** de datos independientes
- **Modularidad** y composiciÃ³n de procesos

---

## ğŸ”„ Flujo de Datos y OrquestaciÃ³n

### **ConstrucciÃ³n de Cadenas de Dependencia**

```csharp
// Algoritmo recursivo para construir Ã¡rbol jerÃ¡rquico
public static List<PipelineUnitChain> DefinePipelineUnitsChain(List<PipelineUnit> units) {
    return new Orchestator().getChildren(null, rawUnits);
}
```

**Proceso:**
1. **Identificar raÃ­ces**: Units con `PipelineUnitId == null`
2. **Construir recursivamente**: Para cada unit, encontrar sus hijos
3. **Crear cadenas**: Estructura jerÃ¡rquica para ejecuciÃ³n ordenada

### **Flujo de Outputs Entre Unidades**

```
QueryRunner (extrae BD) â†’ genera data.csv â†’ _output: ["/temp/data.csv"]
    â†“ lastOutput
ZipRunner (comprime) â†’ procesa data.csv â†’ _output: ["/temp/archive.zip"]
    â†“ lastOutput  
SFTPUploader (envÃ­a) â†’ sube archive.zip â†’ _output: ["/remote/archive.zip"]
    â†“ lastOutput
CommandRunner (valida) â†’ verifica upload â†’ _output: ["Upload successful"]
```

### **PatrÃ³n de Reintentos Configurables**

```csharp
public RunnerOutput RunWithRetry(PipelineUnit unit, RunnerOutput _lastOutput, int tryCount = 0) {
    var runResult = Run(unit, _lastOutput);
    if (runResult.HasErrors) {
        if (tryCount + 1 <= unit.RetryCount) {
            Thread.Sleep(unit.RetryAfterMilliseconds);
            return RunWithRetry(unit, _lastOutput, tryCount: tryCount + 1);
        }
        // FallÃ³ despuÃ©s de todos los reintentos
        return null;
    }
    return runResult;
}
```

---

## ğŸ“Š Sistema de Actualizaciones AutomÃ¡ticas

### **VerificaciÃ³n y Descarga**

```csharp
// 1. Consultar Hasura por nuevas versiones
var merlinAgentUpdate = await hasura.GetMerlinAgentVersion();

// 2. Descargar con timeout configurable (60 min default)
await MerlinHttpHelper.DownloadFileAsync(updateUrl, localPath, timeOutMinutes: 60);

// 3. Aplicar actualizaciÃ³n
MerlinUpdater updater = new MerlinUpdater(merlinAgentUpdate.AgentVersion);
bool successUpdate = await updater.PerformUpdate();

// 4. Auto-limpieza si estÃ¡ habilitada
if (successUpdate && merlinAgentUpdate.AutoCleanUpdate) {
    AutoClean autoClean = new AutoClean();
    autoClean.Clean();
}

// 5. Reportar resultado y reiniciar
await hasura.InformAgentUpdateResult(updateLog);
if (successUpdate) {
    Environment.Exit(1); // SIGTERM para restart por service manager
}
```

**CaracterÃ­sticas:**
- **3 URLs de respaldo** para alta disponibilidad
- **ValidaciÃ³n post-descarga** del archivo
- **Auto-limpieza** configurable de archivos temporales
- **Reinicio controlado** para aplicar updates sin intervenciÃ³n manual

---

## ğŸ—„ï¸ IntegraciÃ³n con Hasura GraphQL

### **Operaciones de Escritura del Agente**
1. **AgentPassportPing**: Heartbeat con informaciÃ³n del sistema
2. **SetRunningStateJob**: Marcar job como ejecutÃ¡ndose
3. **InformPipelineJobResults**: Enviar mÃ©tricas de timing (PipelineJobLogV2)
4. **CollectMemoryLogs**: Enviar logs detallados (PipelineJobLogV2Body)
5. **CompletePipelineJob**: Marcar job como completado/fallido
6. **InformAgentUpdateResult**: Reportar resultado de actualizaciÃ³n
7. **InsertPipelineJobQueue**: Crear nuevos jobs (CallPipeline runner)

### **Operaciones de Lectura del Agente**
1. **GetMerlinAgentVersion**: Consultar por actualizaciones disponibles
2. **GetMerlinAgentPipelineJob**: Obtener prÃ³ximo job a ejecutar

### **Sistema de Logging Dual**

#### **PipelineJobLogV2 - MÃ©tricas de Timing**
```csharp
pipelineJobLogs.Add(new PipelineJobLog() {
    PipelineUnitId = unit.Id,
    PipelineJobQueueId = jobId,
    LogOrder = this.logOrder,           // Orden de ejecuciÃ³n
    MilliSeconds = watch.ElapsedMilliseconds  // Tiempo de ejecuciÃ³n
});
```

#### **PipelineJobLogV2Body - Logs Detallados**
```json
{
  "pipeline_job_id": "uuid-job-id",
  "pipeline_unit_id": "uuid-unit-id", 
  "pipeline_unit_context_id": "query_id:123",
  "date": "2025-05-27T23:51:15.000+00:00",
  "level": "INFO",
  "message": "Ejecutando consulta SQL exitosamente.",
  "callsite": "QueryQueueRunner.Execute",
  "exception": null,
  "exception_message": null,
  "exception_stack_trace": null
}
```

---

## ğŸ¯ Casos de Uso Empresariales

### **1. Pipeline de ExtracciÃ³n y DistribuciÃ³n**
```
QueryRunner (extrae ventas diarias) 
â†’ ZipRunner (comprime reportes)
â†’ SFTPUploader (envÃ­a a sucursales)
â†’ CommandRunner (genera notificaciÃ³n)
```

### **2. Pipeline de Procesamiento ETL**
```
SFTPDownloader (descarga archivos externos)
â†’ ZipRunner (descomprime datos)
â†’ CommandRunner (ejecuta transformaciÃ³n Python)
â†’ QueryRunner (inserta a data warehouse)
```

### **3. Pipeline de ConsolidaciÃ³n Recursiva**
```
QueryRunner (consulta inicial)
â†’ PipelineCallRunner (llama procesamiento por regiÃ³n)
    â”œâ”€â”€ Pipeline RegiÃ³n Norte
    â”œâ”€â”€ Pipeline RegiÃ³n Sur  
    â””â”€â”€ Pipeline RegiÃ³n Centro
â†’ QueryRunner (consolida resultados finales)
```

### **4. Pipeline de Backup y Mantenimiento**
```
QueryRunner (exporta backups)
â†’ ZipRunner (comprime con password)
â†’ SFTPUploader (envÃ­a a storage remoto)
â†’ CommandRunner (limpia archivos locales antiguos)
```

---

## ğŸš€ CaracterÃ­sticas ArquitectÃ³nicas Clave

### **Escalabilidad Horizontal**
- **Agentes independientes** sin coordinaciÃ³n entre ellos
- **Hasura como coordinador** central escalable
- **Pipelines recursivos** para distribuciÃ³n de carga
- **MÃºltiples agentes** pueden procesar diferentes pipelines simultÃ¡neamente

### **Confiabilidad Empresarial**
- **Heartbeat continuo** para detecciÃ³n inmediata de fallos
- **Reintentos automÃ¡ticos** configurables por operaciÃ³n
- **Cola de respaldo** para logs cuando hay problemas de conectividad
- **Timeouts granulares** por tipo de operaciÃ³n
- **ActualizaciÃ³n automÃ¡tica** sin intervenciÃ³n manual

### **Observabilidad Completa**
- **Logging dual** para mÃ©tricas y contenido detallado
- **Contexto enriquecido** con PipelineJobId, PipelineUnitId, ContextId
- **Dashboard en tiempo real** con WebSocket para updates instantÃ¡neos
- **Trazabilidad completa** del flujo de datos entre unidades

### **Flexibilidad de ConfiguraciÃ³n**
- **5 tipos de runners** para diferentes tipos de operaciones
- **ConfiguraciÃ³n granular** de reintentos, timeouts, y comportamiento de errores
- **Flujo de datos explÃ­cito** entre unidades con outputs tipados
- **Modos de despliegue** flexibles para diferentes entornos

### **Seguridad y Mantenibilidad**
- **Operaciones read-only** del dashboard para proteger datos crÃ­ticos
- **Variables de entorno** para configuraciÃ³n sensible
- **Auto-limpieza** de archivos temporales
- **Actualizaciones centralizadas** desde Hasura
- **Bypass SSL** configurable para entornos corporativos

---

## ğŸ“ˆ MÃ©tricas de Performance

### **Optimizaciones Implementadas**
- **Logging asÃ­ncrono** con batches de 1000 logs
- **Polling eficiente** de jobs con intervalos optimizados  
- **ReutilizaciÃ³n de conexiones** HTTP para downloads
- **CompresiÃ³n Ã³ptima** automÃ¡tica para archivos
- **Memory buffering** para logs de alta frecuencia

### **LÃ­mites y Configuraciones**
- **Timeout de descarga**: 60 minutos (configurable)
- **RotaciÃ³n de logs**: 5MB por archivo, 5 archivos histÃ³ricos
- **Cola de respaldo**: MÃ¡ximo 100 bloques de logs
- **Batch size**: 1000 logs por escritura asÃ­ncrona
- **Heartbeat**: Cada ~60 segundos por agente

---

## ğŸ¯ Consideraciones de Arquitectura

### **Puntos Fuertes**
1. **DistribuciÃ³n real**: Agentes completamente autÃ³nomos
2. **Resilencia**: Sistema de respaldo y recuperaciÃ³n automÃ¡tica  
3. **Trazabilidad**: Logging completo con contexto estructurado
4. **Flexibilidad**: 5 tipos de runners + recursividad
5. **Mantenimiento**: Actualizaciones automÃ¡ticas centralizadas

### **Puntos de AtenciÃ³n**
1. **Dependencia de Hasura**: Coordinador central crÃ­tico
2. **Complejidad**: Sistema con mÃºltiples componentes interconectados
3. **Recursos**: 4 workers por agente requieren recursos adecuados
4. **Red**: Conectividad estable requerida para operaciÃ³n Ã³ptima

### **Escalabilidad Future-Proof**
- **Nuevos tipos de runners** fÃ¡cilmente extensibles
- **MÃºltiples coordinadores** Hasura para redundancia geogrÃ¡fica
- **Sharding** de agentes por regiÃ³n o funcionalidad
- **MÃ©tricas avanzadas** para optimizaciÃ³n de performance

---

Este sistema representa una arquitectura robusta y escalable para automatizaciÃ³n empresarial, combinando la flexibilidad de agentes distribuidos con la potencia de un coordinador centralizado GraphQL, todo monitoreado a travÃ©s de un dashboard en tiempo real con capacidades de diseÃ±o visual de pipelines.